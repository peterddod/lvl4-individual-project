{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Algorithm Testing\n",
    "A notebook used to compare algorithm performance.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Imports\n",
    "from nitools import utils \n",
    "from nitools.classifiers import PAE_RVFL, ELM, AE_ELM \n",
    "from nitools.models import LeNet5, ResNet18\n",
    "from nitools.operations import resetseed\n",
    "\n",
    "import numpy as np\n",
    "import random\n",
    "import torch\n",
    "import time as t"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. MNIST\n",
    "\n",
    "Dataset of greyscale 28x28 images of handwritten digits. \n",
    "\n",
    "*Train: 60,000*, *Test: 10,000*, *10 Classes*, *784 Inputs*\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import dataset\n",
    "mnist = utils.load_mnist()\n",
    "\n",
    "mnist_in = 784\n",
    "mnist_class = 10"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### pAE-RVFL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "conv2d() received an invalid combination of arguments - got (Tensor, list, NoneType, padding=int, stride=int), but expected one of:\n * (Tensor input, Tensor weight, Tensor bias, tuple of ints stride, tuple of ints padding, tuple of ints dilation, int groups)\n * (Tensor input, Tensor weight, Tensor bias, tuple of ints stride, str padding, tuple of ints dilation, int groups)\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "File \u001b[0;32m~/repos/lvl4-individual-project/src/nitools/architecture/Pipeline.py:21\u001b[0m, in \u001b[0;36mPipeline.train\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m---> 21\u001b[0m     temp \u001b[38;5;241m=\u001b[39m \u001b[43mmodule\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     22\u001b[0m     X \u001b[38;5;241m=\u001b[39m temp\n",
      "File \u001b[0;32m~/repos/lvl4-individual-project/src/nitools/convolution/Conv2D.py:23\u001b[0m, in \u001b[0;36mConv2D.train\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m     22\u001b[0m X\u001b[38;5;241m.\u001b[39mdetach()\n\u001b[0;32m---> 23\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_weights \u001b[38;5;241m=\u001b[39m \u001b[43mfiltersynth\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_out_channels\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_kernel_size\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstride\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_stride\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     25\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m conv2d(X, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_weights, \u001b[38;5;28;01mNone\u001b[39;00m, stride\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_stride, padding\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_padding)\n",
      "File \u001b[0;32m~/repos/lvl4-individual-project/src/nitools/operations.py:97\u001b[0m, in \u001b[0;36mfiltersynth\u001b[0;34m(X, k, s, stride, padding)\u001b[0m\n\u001b[1;32m     95\u001b[0m             block \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mreshape(X[:, c, h:h\u001b[38;5;241m+\u001b[39ms, w:w\u001b[38;5;241m+\u001b[39ms], (in_size[\u001b[38;5;241m0\u001b[39m], s\u001b[38;5;241m*\u001b[39ms))\u001b[38;5;241m.\u001b[39mdetach()\n\u001b[0;32m---> 97\u001b[0m             kmeans \u001b[38;5;241m=\u001b[39m \u001b[43mkmeans\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpartial_fit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mblock\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     99\u001b[0m \u001b[38;5;66;03m# use centroids as kernels - (out_channels, in_channels, kH, kW)\u001b[39;00m\n",
      "File \u001b[0;32m~/miniforge3/envs/ml/lib/python3.9/site-packages/sklearn/cluster/_kmeans.py:2097\u001b[0m, in \u001b[0;36mMiniBatchKMeans.partial_fit\u001b[0;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[1;32m   2096\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m threadpool_limits(limits\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m, user_api\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mblas\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[0;32m-> 2097\u001b[0m     \u001b[43m_mini_batch_step\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   2098\u001b[0m \u001b[43m        \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2099\u001b[0m \u001b[43m        \u001b[49m\u001b[43mx_squared_norms\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mx_squared_norms\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2100\u001b[0m \u001b[43m        \u001b[49m\u001b[43msample_weight\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msample_weight\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2101\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcenters\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcluster_centers_\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2102\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcenters_new\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcluster_centers_\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2103\u001b[0m \u001b[43m        \u001b[49m\u001b[43mweight_sums\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_counts\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2104\u001b[0m \u001b[43m        \u001b[49m\u001b[43mrandom_state\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_random_state\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2105\u001b[0m \u001b[43m        \u001b[49m\u001b[43mrandom_reassign\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_random_reassign\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2106\u001b[0m \u001b[43m        \u001b[49m\u001b[43mreassignment_ratio\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreassignment_ratio\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2107\u001b[0m \u001b[43m        \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mverbose\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2108\u001b[0m \u001b[43m        \u001b[49m\u001b[43mn_threads\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_n_threads\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2109\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2111\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcompute_labels:\n",
      "File \u001b[0;32m~/miniforge3/envs/ml/lib/python3.9/site-packages/sklearn/cluster/_kmeans.py:1446\u001b[0m, in \u001b[0;36m_mini_batch_step\u001b[0;34m(X, x_squared_norms, sample_weight, centers, centers_new, weight_sums, random_state, random_reassign, reassignment_ratio, verbose, n_threads)\u001b[0m\n\u001b[1;32m   1443\u001b[0m \u001b[38;5;66;03m# Perform label assignment to nearest centers\u001b[39;00m\n\u001b[1;32m   1444\u001b[0m \u001b[38;5;66;03m# For better efficiency, it's better to run _mini_batch_step in a\u001b[39;00m\n\u001b[1;32m   1445\u001b[0m \u001b[38;5;66;03m# threadpool_limit context than using _labels_inertia_threadpool_limit here\u001b[39;00m\n\u001b[0;32m-> 1446\u001b[0m labels, inertia \u001b[38;5;241m=\u001b[39m \u001b[43m_labels_inertia\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1447\u001b[0m \u001b[43m    \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msample_weight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mx_squared_norms\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcenters\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_threads\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mn_threads\u001b[49m\n\u001b[1;32m   1448\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1450\u001b[0m \u001b[38;5;66;03m# Update centers according to the labels\u001b[39;00m\n",
      "File \u001b[0;32m~/miniforge3/envs/ml/lib/python3.9/site-packages/sklearn/cluster/_kmeans.py:746\u001b[0m, in \u001b[0;36m_labels_inertia\u001b[0;34m(X, sample_weight, x_squared_norms, centers, n_threads)\u001b[0m\n\u001b[1;32m    733\u001b[0m _labels(\n\u001b[1;32m    734\u001b[0m     X,\n\u001b[1;32m    735\u001b[0m     sample_weight,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    743\u001b[0m     update_centers\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[1;32m    744\u001b[0m )\n\u001b[0;32m--> 746\u001b[0m inertia \u001b[38;5;241m=\u001b[39m \u001b[43m_inertia\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msample_weight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcenters\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlabels\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_threads\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    748\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m labels, inertia\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: ",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[0;32mIn [5]\u001b[0m, in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     17\u001b[0m y \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mfrom_numpy(mnist[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtrain_y\u001b[39m\u001b[38;5;124m'\u001b[39m])\u001b[38;5;241m.\u001b[39mfloat()[:\u001b[38;5;241m60000\u001b[39m]\n\u001b[1;32m     19\u001b[0m train_start \u001b[38;5;241m=\u001b[39m t\u001b[38;5;241m.\u001b[39mtime()\n\u001b[0;32m---> 20\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[43mlenet\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     21\u001b[0m train_end \u001b[38;5;241m=\u001b[39m t\u001b[38;5;241m.\u001b[39mtime()\n\u001b[1;32m     22\u001b[0m tX \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mfrom_numpy(mnist[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtest_X\u001b[39m\u001b[38;5;124m'\u001b[39m])\u001b[38;5;241m.\u001b[39mfloat()\n",
      "File \u001b[0;32m~/repos/lvl4-individual-project/src/nitools/models/LeNet5.py:56\u001b[0m, in \u001b[0;36mLeNet5.train\u001b[0;34m(self, X, y)\u001b[0m\n\u001b[1;32m     53\u001b[0m w_h \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mint\u001b[39m(np\u001b[38;5;241m.\u001b[39msqrt(X\u001b[38;5;241m.\u001b[39msize()[\u001b[38;5;241m1\u001b[39m]))\n\u001b[1;32m     54\u001b[0m n \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mint\u001b[39m(X\u001b[38;5;241m.\u001b[39msize()[\u001b[38;5;241m0\u001b[39m])\n\u001b[0;32m---> 56\u001b[0m X \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_model\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreshape\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mn\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mw_h\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mw_h\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     57\u001b[0m C \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mreshape(X, (n, w_h\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m2\u001b[39m))\u001b[38;5;241m.\u001b[39mdetach()\n\u001b[1;32m     59\u001b[0m H \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_classifier\u001b[38;5;241m.\u001b[39mtrain(C, y)\n",
      "File \u001b[0;32m~/repos/lvl4-individual-project/src/nitools/architecture/Pipeline.py:24\u001b[0m, in \u001b[0;36mPipeline.train\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m     22\u001b[0m         X \u001b[38;5;241m=\u001b[39m temp\n\u001b[1;32m     23\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m:\n\u001b[0;32m---> 24\u001b[0m         temp \u001b[38;5;241m=\u001b[39m \u001b[43mmodule\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     25\u001b[0m         X \u001b[38;5;241m=\u001b[39m temp\n\u001b[1;32m     28\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m X\n",
      "File \u001b[0;32m~/repos/lvl4-individual-project/src/nitools/convolution/Conv2D.py:16\u001b[0m, in \u001b[0;36mConv2D.__call__\u001b[0;34m(self, arg)\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m, arg):\n\u001b[0;32m---> 16\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mforward\u001b[49m\u001b[43m(\u001b[49m\u001b[43marg\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/repos/lvl4-individual-project/src/nitools/convolution/Conv2D.py:19\u001b[0m, in \u001b[0;36mConv2D.forward\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, X):\n\u001b[0;32m---> 19\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mconv2d\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_weights\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstride\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_stride\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpadding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_padding\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mTypeError\u001b[0m: conv2d() received an invalid combination of arguments - got (Tensor, list, NoneType, padding=int, stride=int), but expected one of:\n * (Tensor input, Tensor weight, Tensor bias, tuple of ints stride, tuple of ints padding, tuple of ints dilation, int groups)\n * (Tensor input, Tensor weight, Tensor bias, tuple of ints stride, str padding, tuple of ints dilation, int groups)\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cpu\")\n",
    "\n",
    "SEED = 22\n",
    "resetseed(SEED)\n",
    "\n",
    "pae_rvfl = PAE_RVFL.PAE_RVFL(\n",
    "    784, \n",
    "    400, \n",
    "    mnist_class, \n",
    "    subnets=1,\n",
    "    device=device, \n",
    "    r=(1,1), sc=0.5, sb=0.5, c=1000, ae_iters=3)\n",
    "\n",
    "lenet = LeNet5.LeNet5(pae_rvfl, weight_train=True)\n",
    "\n",
    "X = torch.from_numpy(mnist['train_X']).float()[:60000]\n",
    "y = torch.from_numpy(mnist['train_y']).float()[:60000]\n",
    "\n",
    "train_start = t.time()\n",
    "result = lenet.train(X, y)\n",
    "train_end = t.time()\n",
    "tX = torch.from_numpy(mnist['test_X']).float()\n",
    "pred = lenet.predict(tX)[:10000]\n",
    "pred_arg = np.zeros(10000)\n",
    "\n",
    "for i in range(len(pred)):\n",
    "    pred_arg[i] = np.argmax(pred[i])\n",
    "\n",
    "print(f\"train: {train_end-train_start}\")\n",
    "utils.evaluation_summary('lenet PAE-RVFL - MNIST', pred_arg, mnist['test_y'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ELM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "The size of tensor a (10) must match the size of tensor b (6) at non-singleton dimension 3",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "File \u001b[0;32m~/repos/lvl4-individual-project/src/nitools/architecture/Pipeline.py:21\u001b[0m, in \u001b[0;36mPipeline.train\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m---> 21\u001b[0m     temp \u001b[38;5;241m=\u001b[39m \u001b[43mmodule\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     22\u001b[0m     X \u001b[38;5;241m=\u001b[39m temp\n",
      "File \u001b[0;32m~/repos/lvl4-individual-project/src/nitools/convolution/ResConv2D.py:26\u001b[0m, in \u001b[0;36mResConv2D.train\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m     25\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mtrain\u001b[39m(\u001b[38;5;28mself\u001b[39m, X):\n\u001b[0;32m---> 26\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43madd\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_layer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: The size of tensor a (10) must match the size of tensor b (6) at non-singleton dimension 3",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Input \u001b[0;32mIn [9]\u001b[0m, in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     14\u001b[0m y \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mfrom_numpy(mnist[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtrain_y\u001b[39m\u001b[38;5;124m'\u001b[39m])\u001b[38;5;241m.\u001b[39mfloat()[:\u001b[38;5;241m5000\u001b[39m]\n\u001b[1;32m     16\u001b[0m train_start \u001b[38;5;241m=\u001b[39m t\u001b[38;5;241m.\u001b[39mtime()\n\u001b[0;32m---> 17\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[43mlenet\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     18\u001b[0m train_end \u001b[38;5;241m=\u001b[39m t\u001b[38;5;241m.\u001b[39mtime()\n\u001b[1;32m     19\u001b[0m tX \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mfrom_numpy(mnist[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtest_X\u001b[39m\u001b[38;5;124m'\u001b[39m])\u001b[38;5;241m.\u001b[39mfloat()\n",
      "File \u001b[0;32m~/repos/lvl4-individual-project/src/nitools/models/ResNet18.py:41\u001b[0m, in \u001b[0;36mResNet18.train\u001b[0;34m(self, X, y)\u001b[0m\n\u001b[1;32m     38\u001b[0m w_h \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mint\u001b[39m(np\u001b[38;5;241m.\u001b[39msqrt(X\u001b[38;5;241m.\u001b[39msize()[\u001b[38;5;241m1\u001b[39m]))\n\u001b[1;32m     39\u001b[0m n \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mint\u001b[39m(X\u001b[38;5;241m.\u001b[39msize()[\u001b[38;5;241m0\u001b[39m])\n\u001b[0;32m---> 41\u001b[0m X \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_model\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreshape\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mn\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mw_h\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mw_h\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     42\u001b[0m C \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mreshape(X, (n, w_h\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m2\u001b[39m))\u001b[38;5;241m.\u001b[39mdetach()\n\u001b[1;32m     44\u001b[0m H \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_classifier\u001b[38;5;241m.\u001b[39mtrain(C, y)\n",
      "File \u001b[0;32m~/repos/lvl4-individual-project/src/nitools/architecture/Pipeline.py:24\u001b[0m, in \u001b[0;36mPipeline.train\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m     22\u001b[0m         X \u001b[38;5;241m=\u001b[39m temp\n\u001b[1;32m     23\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m:\n\u001b[0;32m---> 24\u001b[0m         temp \u001b[38;5;241m=\u001b[39m \u001b[43mmodule\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     25\u001b[0m         X \u001b[38;5;241m=\u001b[39m temp\n\u001b[1;32m     28\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m X\n",
      "File \u001b[0;32m~/repos/lvl4-individual-project/src/nitools/convolution/ResConv2D.py:20\u001b[0m, in \u001b[0;36mResConv2D.__call__\u001b[0;34m(self, arg)\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m, arg):\n\u001b[0;32m---> 20\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mforward\u001b[49m\u001b[43m(\u001b[49m\u001b[43marg\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/repos/lvl4-individual-project/src/nitools/convolution/ResConv2D.py:23\u001b[0m, in \u001b[0;36mResConv2D.forward\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, X):\n\u001b[0;32m---> 23\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43madd\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_layer\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: The size of tensor a (10) must match the size of tensor b (6) at non-singleton dimension 3"
     ]
    }
   ],
   "source": [
    "SEED = 22\n",
    "resetseed(SEED)\n",
    "\n",
    "# Get ELM results\n",
    "mnist_elm = AE_ELM.AE_ELM(  # TODO: batchnorm input weights to ae?\n",
    "    input_size=mnist_in,\n",
    "    h_size=100,\n",
    "    output_size=mnist_class,\n",
    "    ae_iters=3)\n",
    "\n",
    "lenet = ResNet18.ResNet18(mnist_elm, weight_train=True)\n",
    "\n",
    "X = torch.from_numpy(mnist['train_X']).float()[:5000]\n",
    "y = torch.from_numpy(mnist['train_y']).float()[:5000]\n",
    "\n",
    "train_start = t.time()\n",
    "result = lenet.train(X, y)\n",
    "train_end = t.time()\n",
    "tX = torch.from_numpy(mnist['test_X']).float()\n",
    "pred = lenet.predict(tX)[:10000]\n",
    "pred_arg = np.zeros(10000)\n",
    "\n",
    "for i in range(len(pred)):\n",
    "    pred_arg[i] = np.argmax(pred[i])\n",
    "\n",
    "\n",
    "print(f\"train: {train_end-train_start}\")\n",
    "utils.evaluation_summary('lenet AE-ELM - MNIST', pred_arg, mnist['test_y'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SEED = 22\n",
    "resetseed(SEED)\n",
    "\n",
    "# Get ELM results\n",
    "mnist_elm = ELM.ELM(  # TODO: batchnorm input weights to ae?\n",
    "    input_size=mnist_in,\n",
    "    h_size=1000,\n",
    "    output_size=mnist_class)\n",
    "\n",
    "lenet = LeNet5.LeNet5(mnist_elm, weight_train=True)\n",
    "\n",
    "X = torch.from_numpy(mnist['train_X']).float()[:60000]\n",
    "y = torch.from_numpy(mnist['train_y']).float()[:60000]\n",
    "\n",
    "train_start = t.time()\n",
    "result = lenet.train(X, y)\n",
    "train_end = t.time()\n",
    "tX = torch.from_numpy(mnist['test_X']).float()\n",
    "pred = lenet.predict(tX)[:10000]\n",
    "pred_arg = np.zeros(10000)\n",
    "\n",
    "for i in range(len(pred)):\n",
    "    pred_arg[i] = np.argmax(pred[i])\n",
    "\n",
    "\n",
    "print(f\"train: {train_end-train_start}\")\n",
    "utils.evaluation_summary('lenet  - MNIST', pred_arg, mnist['test_y'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. CIFAR-10\n",
    "\n",
    "Dataset of colour (3-dimension) 32x32 images of objects of 10 classes:\n",
    "\n",
    "0.\tairplane\n",
    "1.\tautomobile\n",
    "2.\tbird\n",
    "3.\tcat\n",
    "4.\tdeer\n",
    "5.\tdog\n",
    "6.\tfrog\n",
    "7.\thorse\n",
    "8.\tship\n",
    "9.\ttruck\n",
    "\n",
    "*Train: 60,000*, *Test: 10,000*, *10 Classes*, *784 Inputs*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import dataset\n",
    "cifar10 = utils.load_cifar10()\n",
    "\n",
    "cifar_in = 32*32*3\n",
    "cifar_class = 10"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SPAE-RVFL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cpu\")\n",
    "\n",
    "pae_rvfl = SPAE_RVFL.SPAE_RVFL(\n",
    "    cifar_in, \n",
    "    cifar_class, \n",
    "    [100], \n",
    "    subnets=[5], \n",
    "    device=device, \n",
    "    r=[(1,1), (1,1)], sc=0.5, sb=0.5)\n",
    "\n",
    "lenet = LeNet5.LeNet5_3D(pae_rvfl)\n",
    "\n",
    "X = torch.from_numpy(cifar10['train_X']).float()[:5000]\n",
    "y = torch.from_numpy(cifar10['train_y']).float()[:5000]\n",
    "\n",
    "result = lenet.train(X, y)\n",
    "tX = torch.from_numpy(cifar10['test_X']).float()\n",
    "pred = lenet.predict(tX)[:10000]\n",
    "pred_arg = np.zeros(10000)\n",
    "\n",
    "for i in range(len(pred)):\n",
    "    pred_arg[i] = np.argmax(pred[i])\n",
    "\n",
    "utils.evaluation_summary('lenet PAE-RVFL - MNIST', pred_arg, cifar10['test_y'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
