{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Algorithm Testing\n",
    "A notebook used to compare algorithm performance.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Imports\n",
    "from nitools import utils \n",
    "from nitools.classifiers import PAE_RVFL, ELM, AE_ELM, PAE_ELM\n",
    "from nitools.models import LeNetPlus, LRF_ELM, LRF_ELMplus, MiniRes\n",
    "from nitools.operations import resetseed\n",
    "\n",
    "import numpy as np\n",
    "import random\n",
    "import torch\n",
    "import time as t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Import dataset\n",
    "mnist = utils.load_mnist(augment=True)\n",
    "\n",
    "mnist_in = 784\n",
    "mnist_class = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run(model, n=10000, nt=10000, data=mnist):\n",
    "    X = None\n",
    "    y = None \n",
    "    tX = None\n",
    "    try:\n",
    "        X = data['train_X'].float()[:n]\n",
    "        y = data['train_y'].float()[:n]\n",
    "        tX = data['test_X'].float()[:nt]\n",
    "    except:\n",
    "        X = data['train_X'].view((50000,3,32,32)).float()[:n]\n",
    "        y = torch.from_numpy(data['train_y']).float()[:n]\n",
    "        tX = data['test_X'].view((10000,3,32,32)).float()\n",
    "\n",
    "    train_start = t.time()\n",
    "    result = model.train(X, y)\n",
    "    train_end = t.time()\n",
    "    \n",
    "\n",
    "    test_start = t.time()\n",
    "    pred = model.predict(tX)\n",
    "    test_end = t.time()\n",
    "\n",
    "    pred_arg = np.zeros(nt)\n",
    "\n",
    "    for i in range(len(pred)):\n",
    "        pred_arg[i] = np.argmax(pred[i])\n",
    "\n",
    "\n",
    "    print(f\"train: {train_end-train_start}\")\n",
    "    print(f\"test: {test_end-test_start}\")\n",
    "    utils.evaluation_summary('lenet  - MNIST', pred_arg, data['test_y'][:nt])\n",
    "    \n",
    "def runos(model, b=5000, iters=1, nt=10000, data=mnist):\n",
    "    X = torch.from_numpy(data['train_X']).view((60000,1,28,28)).float()\n",
    "    y = torch.from_numpy(data['train_y']).float()\n",
    "\n",
    "    train_start = t.time()\n",
    "    for i in range(0,60000,b):\n",
    "        if i/b==iters:\n",
    "            break\n",
    "        result = model.train(X[i:i+b], y[i:i+b])\n",
    "    train_end = t.time()\n",
    "    \n",
    "    tX = torch.from_numpy(data['test_X']).view((10000,1,28,28)).float()\n",
    "\n",
    "    test_start = t.time()\n",
    "    pred = model.predict(tX)[:nt]\n",
    "    test_end = t.time()\n",
    "\n",
    "    pred_arg = np.zeros(nt)\n",
    "\n",
    "    for i in range(len(pred)):\n",
    "        pred_arg[i] = np.argmax(pred[i])\n",
    "\n",
    "\n",
    "    print(f\"train: {train_end-train_start}\")\n",
    "    print(f\"test: {test_end-test_start}\")\n",
    "    utils.evaluation_summary('lenet  - MNIST', pred_arg, data['test_y'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. MNIST\n",
    "\n",
    "Dataset of greyscale 28x28 images of handwritten digits. \n",
    "\n",
    "*Train: 60,000*, *Test: 10,000*, *10 Classes*, *784 Inputs*\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([5000, 3072])\n",
      "train: 5.931313991546631\n",
      "test: 8.877159118652344\n",
      "Evaluation for: lenet  - MNIST\n",
      "Classifier 'lenet  - MNIST' has Acc=0.859 P=0.859 R=0.859 F1=0.859\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0      0.798     0.816     0.807       978\n",
      "         1.0      0.965     0.993     0.979       972\n",
      "         2.0      0.769     0.758     0.763      1015\n",
      "         3.0      0.880     0.852     0.866      1033\n",
      "         4.0      0.764     0.740     0.752      1032\n",
      "         5.0      0.947     0.959     0.953       988\n",
      "         6.0      0.614     0.636     0.625       965\n",
      "         7.0      0.945     0.930     0.937      1016\n",
      "         8.0      0.953     0.953     0.953      1000\n",
      "         9.0      0.955     0.954     0.955      1001\n",
      "\n",
      "    accuracy                          0.859     10000\n",
      "   macro avg      0.859     0.859     0.859     10000\n",
      "weighted avg      0.859     0.859     0.859     10000\n",
      "\n",
      "\n",
      "Confusion matrix:\n",
      " [[798   0  17  40   9   1 120   0  13   2]\n",
      " [  1 965   2  18   4   2   5   0   3   0]\n",
      " [ 16   1 769  12 112   1  85   0   4   0]\n",
      " [ 18   3  18 880  37   0  42   0   2   0]\n",
      " [  2   0 115  37 764   1  77   1   3   0]\n",
      " [  2   0   0   2   1 947   2  31   1  14]\n",
      " [138   2  90  34 101   1 614   0  19   1]\n",
      " [  0   0   1   0   0  25   0 945   1  28]\n",
      " [  3   1   3  10   4   1  19   5 953   1]\n",
      " [  0   0   0   0   0   9   1  34   1 955]]\n"
     ]
    }
   ],
   "source": [
    "data = utils.load_fashionmnist(augment=True, label_smoothing=0.1)\n",
    "SEED = 2359487\n",
    "resetseed(SEED)\n",
    "\n",
    "classifier = PAE_ELM(3072,600,10,subnets=3)\n",
    "\n",
    "model = LeNetPlus(c=10)\n",
    "\n",
    "run(model, n=5000, nt=10000, data=data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = utils.load_mnist(augment=False)\n",
    "SEED = 2359487\n",
    "resetseed(SEED)\n",
    "\n",
    "model = LRF_ELM(c=1000, _lambda=1, p=0)\n",
    "\n",
    "run(model, n=25000, nt=10000, data=data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. CIFAR-10\n",
    "\n",
    "Dataset of colour (3-dimension) 32x32 images of objects of 10 classes:\n",
    "\n",
    "0.\tairplane\n",
    "1.\tautomobile\n",
    "2.\tbird\n",
    "3.\tcat\n",
    "4.\tdeer\n",
    "5.\tdog\n",
    "6.\tfrog\n",
    "7.\thorse\n",
    "8.\tship\n",
    "9.\ttruck\n",
    "\n",
    "*Train: 60,000*, *Test: 10,000*, *10 Classes*, *784 Inputs*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import dataset\n",
    "cifar10 = utils.load_cifar10(scaled=True, augment=True)\n",
    "\n",
    "cifar_in = 32*32*3\n",
    "cifar_class = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.5802966356277466\n",
      "torch.Size([6480])\n",
      "0.8892340064048767\n",
      "torch.Size([6480])\n",
      "torch.Size([10000, 1280])\n"
     ]
    }
   ],
   "source": [
    "SEED = 22\n",
    "resetseed(SEED)\n",
    "\n",
    "model = LRF_ELMplus(in_channels=3, c=100, _lambda=np.sqrt(6))\n",
    "\n",
    "run(model, n=10000, nt=5000, data=cifar10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
