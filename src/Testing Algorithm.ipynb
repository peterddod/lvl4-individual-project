{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Algorithm Testing\n",
    "A notebook used to compare algorithm performance.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Imports\n",
    "from nitools import utils\n",
    "from nitools.classifiers import PAE_RVFL, ELM, AE_ELM, PAE_ELM\n",
    "from nitools.models import LeNetPlus, LRF_ELM, LRF_ELMplus, MiniRes\n",
    "from nitools.operations import resetseed\n",
    "\n",
    "import numpy as np\n",
    "import random\n",
    "import torch\n",
    "import time as t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Import dataset\n",
    "mnist = utils.load_mnist(augment=True)\n",
    "\n",
    "mnist_in = 784\n",
    "mnist_class = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run(model, n=10000, nt=10000, data=mnist):\n",
    "    X = None\n",
    "    y = None \n",
    "    tX = None\n",
    "    try:\n",
    "        X = data['train_X'].float()[:n]\n",
    "        y = data['train_y'].float()[:n]\n",
    "        tX = data['test_X'].float()[:nt]\n",
    "    except:\n",
    "        X = data['train_X'].view((50000,3,32,32)).float()[:n]\n",
    "        y = torch.from_numpy(data['train_y']).float()[:n]\n",
    "        tX = data['test_X'].view((10000,3,32,32)).float()\n",
    "\n",
    "    train_start = t.time()\n",
    "    result = model.train(X, y)\n",
    "    train_end = t.time()\n",
    "    \n",
    "\n",
    "    test_start = t.time()\n",
    "    pred = model.predict(tX)\n",
    "    test_end = t.time()\n",
    "\n",
    "    pred_arg = np.zeros(nt)\n",
    "\n",
    "    for i in range(len(pred)):\n",
    "        pred_arg[i] = np.argmax(pred[i])\n",
    "\n",
    "\n",
    "    print(f\"train: {train_end-train_start}\")\n",
    "    print(f\"test: {test_end-test_start}\")\n",
    "    utils.evaluation_summary('lenet  - MNIST', pred_arg, data['test_y'][:nt])\n",
    "    \n",
    "def runos(model, b=5000, iters=1, nt=10000, data=mnist):\n",
    "    X = torch.from_numpy(data['train_X']).view((60000,1,28,28)).float()\n",
    "    y = torch.from_numpy(data['train_y']).float()\n",
    "\n",
    "    train_start = t.time()\n",
    "    for i in range(0,60000,b):\n",
    "        if i/b==iters:\n",
    "            break\n",
    "        result = model.train(X[i:i+b], y[i:i+b])\n",
    "    train_end = t.time()\n",
    "    \n",
    "    tX = torch.from_numpy(data['test_X']).view((10000,1,28,28)).float()\n",
    "\n",
    "    test_start = t.time()\n",
    "    pred = model.predict(tX)[:nt]\n",
    "    test_end = t.time()\n",
    "\n",
    "    pred_arg = np.zeros(nt)\n",
    "\n",
    "    for i in range(len(pred)):\n",
    "        pred_arg[i] = np.argmax(pred[i])\n",
    "\n",
    "\n",
    "    print(f\"train: {train_end-train_start}\")\n",
    "    print(f\"test: {test_end-test_start}\")\n",
    "    utils.evaluation_summary('lenet  - MNIST', pred_arg, data['test_y'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. MNIST\n",
    "\n",
    "Dataset of greyscale 28x28 images of handwritten digits. \n",
    "\n",
    "*Train: 60,000*, *Test: 10,000*, *10 Classes*, *784 Inputs*\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'utils' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[0;32mIn [1]\u001b[0m, in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0m data \u001b[38;5;241m=\u001b[39m \u001b[43mutils\u001b[49m\u001b[38;5;241m.\u001b[39mload_mnist(augment\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m, label_smoothing\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.1\u001b[39m)\n\u001b[1;32m      2\u001b[0m SEED \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m2359487\u001b[39m\n\u001b[1;32m      3\u001b[0m resetseed(SEED)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'utils' is not defined"
     ]
    }
   ],
   "source": [
    "data = utils.load_mnist(augment=False, label_smoothing=0.1)\n",
    "SEED = 2359487\n",
    "resetseed(SEED)\n",
    "\n",
    "model = LRF_ELM()\n",
    "\n",
    "run(model, n=5000, nt=10000, data=data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'utils' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[0;32mIn [2]\u001b[0m, in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0m data \u001b[38;5;241m=\u001b[39m \u001b[43mutils\u001b[49m\u001b[38;5;241m.\u001b[39mload_mnist(augment\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[1;32m      2\u001b[0m SEED \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m2359487\u001b[39m\n\u001b[1;32m      3\u001b[0m resetseed(SEED)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'utils' is not defined"
     ]
    }
   ],
   "source": [
    "data = utils.load_mnist(augment=False)\n",
    "SEED = 2359487\n",
    "resetseed(SEED)\n",
    "\n",
    "model = LRF_ELM(c=1000, _lambda=1, p=0)\n",
    "\n",
    "run(model, n=25000, nt=10000, data=data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. CIFAR-10\n",
    "\n",
    "Dataset of colour (3-dimension) 32x32 images of objects of 10 classes:\n",
    "\n",
    "0.\tairplane\n",
    "1.\tautomobile\n",
    "2.\tbird\n",
    "3.\tcat\n",
    "4.\tdeer\n",
    "5.\tdog\n",
    "6.\tfrog\n",
    "7.\thorse\n",
    "8.\tship\n",
    "9.\ttruck\n",
    "\n",
    "*Train: 60,000*, *Test: 10,000*, *10 Classes*, *784 Inputs*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import dataset\n",
    "cifar10 = utils.load_cifar10(scaled=True, augment=False)\n",
    "\n",
    "cifar_in = 32*32*3\n",
    "cifar_class = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([500, 64, 30, 30])\n",
      "torch.Size([500, 64, 30, 30])\n",
      "torch.Size([500, 64, 30, 30])\n",
      "torch.Size([500, 64, 14, 14])\n",
      "torch.Size([500, 64, 14, 14])\n",
      "torch.Size([500, 64, 14, 14])\n",
      "torch.Size([500, 64, 14, 14])\n",
      "torch.Size([500, 64, 14, 14])\n",
      "torch.Size([500, 64, 14, 14])\n",
      "torch.Size([500, 64, 14, 14])\n",
      "torch.Size([500, 64, 14, 14])\n",
      "torch.Size([500, 64, 14, 14])\n",
      "torch.Size([500, 64, 14, 14])\n",
      "torch.Size([500, 64, 14, 14])\n",
      "torch.Size([500, 64, 14, 14])\n",
      "torch.Size([500, 128, 16, 16])\n",
      "torch.Size([500, 128, 16, 16])\n",
      "torch.Size([500, 128, 16, 16])\n",
      "torch.Size([500, 128, 7, 7])\n",
      "torch.Size([500, 128, 7, 7])\n",
      "torch.Size([500, 128, 7, 7])\n",
      "torch.Size([500, 128, 7, 7])\n",
      "torch.Size([500, 128, 7, 7])\n",
      "torch.Size([500, 128, 7, 7])\n",
      "torch.Size([500, 128, 7, 7])\n",
      "torch.Size([500, 128, 7, 7])\n",
      "torch.Size([500, 128, 7, 7])\n",
      "torch.Size([500, 128, 7, 7])\n",
      "torch.Size([500, 128, 7, 7])\n",
      "torch.Size([500, 128, 7, 7])\n",
      "torch.Size([500, 256, 9, 9])\n",
      "torch.Size([500, 256, 9, 9])\n",
      "torch.Size([500, 256, 9, 9])\n",
      "torch.Size([500, 256, 4, 4])\n",
      "torch.Size([500, 256, 4, 4])\n",
      "torch.Size([500, 256, 4, 4])\n",
      "torch.Size([500, 256, 4, 4])\n",
      "torch.Size([500, 256, 4, 4])\n",
      "torch.Size([500, 256, 4, 4])\n",
      "torch.Size([500, 256, 4, 4])\n",
      "torch.Size([500, 256, 4, 4])\n",
      "torch.Size([500, 256, 4, 4])\n",
      "torch.Size([500, 256, 4, 4])\n",
      "torch.Size([500, 256, 4, 4])\n",
      "torch.Size([500, 256, 4, 4])\n",
      "torch.Size([500, 512, 6, 6])\n",
      "torch.Size([500, 512, 6, 6])\n",
      "torch.Size([500, 512, 6, 6])\n",
      "torch.Size([500, 512, 6, 6])\n",
      "torch.Size([500, 512, 6, 6])\n",
      "torch.Size([500, 512, 6, 6])\n",
      "torch.Size([500, 512, 6, 6])\n",
      "torch.Size([500, 512, 6, 6])\n",
      "torch.Size([500, 512, 6, 6])\n",
      "torch.Size([500, 512, 6, 6])\n",
      "torch.Size([500, 512, 6, 6])\n",
      "torch.Size([500, 512, 6, 6])\n",
      "torch.Size([500, 512, 6, 6])\n",
      "torch.Size([500, 512, 6, 6])\n",
      "torch.Size([500, 512, 3, 3])\n",
      "torch.Size([500, 4608])\n",
      "torch.Size([500, 4608])\n",
      "train: 8.824660301208496\n",
      "test: 2.1996827125549316\n",
      "Evaluation for: lenet  - MNIST\n",
      "Classifier 'lenet  - MNIST' has Acc=0.162 P=0.166 R=0.160 F1=0.159\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0      0.088     0.125     0.103        40\n",
      "         1.0      0.220     0.191     0.205        47\n",
      "         2.0      0.196     0.159     0.175        63\n",
      "         3.0      0.082     0.095     0.088        42\n",
      "         4.0      0.300     0.197     0.238        61\n",
      "         5.0      0.167     0.200     0.182        40\n",
      "         6.0      0.278     0.163     0.205        92\n",
      "         7.0      0.085     0.100     0.092        40\n",
      "         8.0      0.105     0.158     0.126        38\n",
      "         9.0      0.143     0.216     0.172        37\n",
      "\n",
      "    accuracy                          0.162       500\n",
      "   macro avg      0.166     0.160     0.159       500\n",
      "weighted avg      0.186     0.162     0.168       500\n",
      "\n",
      "\n",
      "Confusion matrix:\n",
      " [[ 5  6  8  5  6  5  7  5  6  4]\n",
      " [ 5  9  3  2  3  3  6  4  6  0]\n",
      " [ 2  5 10  9  5  2  9  3  3  3]\n",
      " [ 2  3  7  4  4  4 13  4  1  7]\n",
      " [ 3  2  4  1 12  1  8  2  4  3]\n",
      " [ 5  5  3  6  4  8  6  7  1  3]\n",
      " [ 2  2  8  6 11  6 15  1  1  2]\n",
      " [ 4  5  7  2  4  4 10  4  4  3]\n",
      " [ 8  3  9  2  8  4  9  4  6  4]\n",
      " [ 4  7  4  5  4  3  9  6  6  8]]\n"
     ]
    }
   ],
   "source": [
    "SEED = 22\n",
    "resetseed(SEED)\n",
    "\n",
    "model = MiniRes(in_channels=3, _lambda=0, a=1000)\n",
    "\n",
    "run(model, n=500, nt=500, data=cifar10)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
