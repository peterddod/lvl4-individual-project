{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.datasets import mnist, cifar10\n",
    "# import tensorflow_datasets as tfds\n",
    "from utils.DOSELM import DOSELM\n",
    "from utils.DRRN import DRRN\n",
    "import numpy as np\n",
    "import torch\n",
    "import time as t\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.metrics import recall_score\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import fbeta_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluation_summary(description, predictions, true_labels):\n",
    "    print(\"Evaluation for: \" + description)\n",
    "    precision = precision_score(predictions, true_labels, average=\"macro\")\n",
    "    recall = recall_score(predictions, true_labels, average=\"macro\")\n",
    "    accuracy = accuracy_score(predictions, true_labels)\n",
    "    f1 = fbeta_score(predictions, true_labels, beta=1, average=\"macro\")\n",
    "    print(\"Classifier '%s' has Acc=%0.3f P=%0.3f R=%0.3f F1=%0.3f\" % (description,accuracy,precision,recall,f1))\n",
    "    print(classification_report(predictions, true_labels, digits=3))\n",
    "    print('\\nConfusion matrix:\\n',confusion_matrix(true_labels, predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scale(X):\n",
    "    return (X - X.mean())/(X.std()*10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def splitdata(x, y, splits=2, first=-1):\n",
    "    length = x.shape[0]\n",
    "\n",
    "    out = []\n",
    "    if first == -1:\n",
    "        splitlen = length // splits\n",
    "        for i in range(splits):\n",
    "            out.append((x[splitlen*i:splitlen*(i+1)], y[splitlen*i:splitlen*(i+1)]))\n",
    "    else:\n",
    "        splits-= 1\n",
    "        split1 = int(length*first)\n",
    "        splitn = (length-split1)//splits\n",
    "        out.append((x[0:split1], y[0:split1]))\n",
    "        for i in range(splits):\n",
    "            a = split1+splitn*i\n",
    "            b = split1+splitn*(i+1)\n",
    "            z = (x[a:b], y[a:b])\n",
    "            out.append(z)\n",
    "    return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "(train_X, train_y), (test_X, test_y) = cifar10.load_data()\n",
    "train_X = scale(np.reshape(train_X.ravel(), (-1,3072)))\n",
    "test_X = scale(np.reshape(test_X.ravel(), (-1,3072)))\n",
    "\n",
    "y = np.zeros([50000,10])\n",
    "\n",
    "for i in range(len(y)):\n",
    "    for j in range(len(y[i])):\n",
    "        if j == train_y[i]:\n",
    "            y[i,j] = 1\n",
    "        else:\n",
    "            y[i,j] = 0\n",
    "            \n",
    "train_y=y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10000\n",
      "Evaluation for: DRRN - MNIST\n",
      "Classifier 'DRRN - MNIST' has Acc=0.381 P=0.381 R=0.373 F1=0.374\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0      0.471     0.433     0.451      1089\n",
      "         1.0      0.468     0.393     0.427      1192\n",
      "         2.0      0.231     0.306     0.263       755\n",
      "         3.0      0.194     0.274     0.227       709\n",
      "         4.0      0.273     0.362     0.311       754\n",
      "         5.0      0.290     0.318     0.303       913\n",
      "         6.0      0.465     0.377     0.417      1232\n",
      "         7.0      0.444     0.427     0.435      1040\n",
      "         8.0      0.547     0.451     0.494      1213\n",
      "         9.0      0.431     0.391     0.410      1103\n",
      "\n",
      "    accuracy                          0.381     10000\n",
      "   macro avg      0.381     0.373     0.374     10000\n",
      "weighted avg      0.403     0.381     0.389     10000\n",
      "\n",
      "\n",
      "Confusion matrix:\n",
      " [[471  60  38  22  22  34  23  49 207  74]\n",
      " [ 57 468  31  39  26  34  44  56  87 158]\n",
      " [105  51 231  67 113  89 153  97  56  38]\n",
      " [ 52  77  76 194  56 171 172  69  57  76]\n",
      " [ 71  44 120  60 273  79 155 120  30  48]\n",
      " [ 55  75  88 136  75 290  96  78  61  46]\n",
      " [ 20  56  83  90  92  82 465  49  22  41]\n",
      " [ 48  71  54  45  66  79  55 444  51  87]\n",
      " [142  90  15  27   6  27  21  21 547 104]\n",
      " [ 68 200  19  29  25  28  48  57  95 431]]\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cpu\")\n",
    "\n",
    "drrn = DRRN(3072, 10, 3500, subnets=1, device=device, r=(0.005, 0.1))\n",
    "\n",
    "X = torch.from_numpy(train_X).float()[:50000]\n",
    "y = torch.from_numpy(train_y).float()[:50000]\n",
    "\n",
    "result = drrn.train(X, y)\n",
    "tX = torch.from_numpy(test_X).float()\n",
    "pred = drrn.predict(tX)[:10000]\n",
    "print(len(test_X))\n",
    "pred_arg = np.zeros(10000)\n",
    "\n",
    "for i in range(len(pred)):\n",
    "    pred_arg[i] = np.argmax(pred[i])\n",
    "\n",
    "evaluation_summary('DRRN - MNIST', pred_arg, test_y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A current problem with the algorithm, it seems, is that the algorithm can only learn roughly as well as the first representation created by the network. It can maintain its performance accross multiple layers but does not improve it. It is possible that improving the performance of the autoencoder might allow for better results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([784, 250])\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "svd_cpu: The algorithm failed to converge because the input matrix is ill-conditioned or has too many repeated singular values (error code: 14).",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-7-a0d992a3562c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     11\u001b[0m     \u001b[0mX\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_numpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m     \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_numpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m     \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdoselm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     14\u001b[0m     \u001b[0mj\u001b[0m\u001b[0;34m+=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mj\u001b[0m\u001b[0;34m==\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/git_repos/lvl4-individual-project/src/utils/DOSELM.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self, X, y)\u001b[0m\n\u001b[1;32m     88\u001b[0m                 \u001b[0mH\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_activation\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtemp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_biases\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     89\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 90\u001b[0;31m             \u001b[0mH_pinv\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpinverse\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mH\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     91\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     92\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_datapoints\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: svd_cpu: The algorithm failed to converge because the input matrix is ill-conditioned or has too many repeated singular values (error code: 14)."
     ]
    }
   ],
   "source": [
    "torch.manual_seed(0)\n",
    "\n",
    "device = torch.device(\"cpu\")\n",
    "doselm = DOSELM(784, 10, [250], device=device)\n",
    "split_data = splitdata(train_X, train_y, 2)\n",
    "\n",
    "train_start = t.time()\n",
    "j = 0\n",
    "\n",
    "for i in split_data:\n",
    "    X = torch.from_numpy(i[0]).float()\n",
    "    y = torch.from_numpy(i[1]).float()\n",
    "    result = doselm.train(X,y)\n",
    "    j+=1\n",
    "    if j==0:\n",
    "        break\n",
    "train_end = t.time()\n",
    "\n",
    "tX = torch.from_numpy(test_X).float()\n",
    "\n",
    "pred_start = t.time()\n",
    "pred = doselm.predict(tX)\n",
    "pred_end = t.time()\n",
    "pred_arg = np.zeros(10000)\n",
    "\n",
    "for i in range(len(pred)):\n",
    "    pred_arg[i] = np.argmax(pred[i])\n",
    "\n",
    "evaluation_summary('ELM', pred_arg, test_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.manual_seed(0)\n",
    "\n",
    "device = torch.device(\"cpu\")\n",
    "doselm = DOSELM(784, 10, [1000], device=device)\n",
    "\n",
    "X = torch.from_numpy(train_X).float()[:60000]\n",
    "y = torch.from_numpy(train_y).float()[:60000]\n",
    "\n",
    "result = doselm.train(X, y)\n",
    "tX = torch.from_numpy(test_X).float()\n",
    "pred = doselm.predict(tX)\n",
    "pred_arg = np.zeros(10000)\n",
    "\n",
    "for i in range(len(pred)):\n",
    "    pred_arg[i] = np.argmax(pred[i])\n",
    "\n",
    "evaluation_summary('ELM', pred_arg, test_y)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
