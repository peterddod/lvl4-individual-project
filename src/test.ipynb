{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.datasets import mnist\n",
    "from utils.DOSELM import DOSELM\n",
    "from utils.DRRN import DRRN\n",
    "import numpy as np\n",
    "import torch\n",
    "import time as t\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.metrics import recall_score\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import fbeta_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluation_summary(description, predictions, true_labels):\n",
    "    print(\"Evaluation for: \" + description)\n",
    "    precision = precision_score(predictions, true_labels, average=\"macro\")\n",
    "    recall = recall_score(predictions, true_labels, average=\"macro\")\n",
    "    accuracy = accuracy_score(predictions, true_labels)\n",
    "    f1 = fbeta_score(predictions, true_labels, beta=1, average=\"macro\")\n",
    "    print(\"Classifier '%s' has Acc=%0.3f P=%0.3f R=%0.3f F1=%0.3f\" % (description,accuracy,precision,recall,f1))\n",
    "    print(classification_report(predictions, true_labels, digits=3))\n",
    "    print('\\nConfusion matrix:\\n',confusion_matrix(true_labels, predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scale(X):\n",
    "    return (X - X.mean())/(X.std()*10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def splitdata(x, y, splits=2, first=-1):\n",
    "    length = x.shape[0]\n",
    "\n",
    "    out = []\n",
    "    if first == -1:\n",
    "        splitlen = length // splits\n",
    "        for i in range(splits):\n",
    "            out.append((x[splitlen*i:splitlen*(i+1)], y[splitlen*i:splitlen*(i+1)]))\n",
    "    else:\n",
    "        splits-= 1\n",
    "        split1 = int(length*first)\n",
    "        splitn = (length-split1)//splits\n",
    "        out.append((x[0:split1], y[0:split1]))\n",
    "        for i in range(splits):\n",
    "            a = split1+splitn*i\n",
    "            b = split1+splitn*(i+1)\n",
    "            z = (x[a:b], y[a:b])\n",
    "            out.append(z)\n",
    "    return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "(train_X, train_y), (test_X, test_y) = mnist.load_data()\n",
    "train_X = scale(np.reshape(train_X.ravel(), (-1,784)))\n",
    "test_X = scale(np.reshape(test_X.ravel(), (-1,784)))\n",
    "\n",
    "y = np.zeros([60000,10])\n",
    "\n",
    "for i in range(len(y)):\n",
    "    for j in range(len(y[i])):\n",
    "        if j == train_y[i]:\n",
    "            y[i,j] = 1\n",
    "        else:\n",
    "            y[i,j] = 0\n",
    "            \n",
    "train_y=y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation for: ELM\n",
      "Classifier 'ELM' has Acc=0.801 P=0.798 R=0.805 F1=0.797\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0      0.900     0.871     0.885      1013\n",
      "         1.0      0.927     0.872     0.899      1206\n",
      "         2.0      0.792     0.788     0.790      1037\n",
      "         3.0      0.851     0.690     0.762      1246\n",
      "         4.0      0.814     0.829     0.821       964\n",
      "         5.0      0.713     0.711     0.712       895\n",
      "         6.0      0.816     0.880     0.847       889\n",
      "         7.0      0.876     0.748     0.807      1205\n",
      "         8.0      0.597     0.844     0.699       688\n",
      "         9.0      0.693     0.816     0.749       857\n",
      "\n",
      "    accuracy                          0.801     10000\n",
      "   macro avg      0.798     0.805     0.797     10000\n",
      "weighted avg      0.812     0.801     0.803     10000\n",
      "\n",
      "\n",
      "Confusion matrix:\n",
      " [[ 882    2   11   12    5   23   17    5   21    2]\n",
      " [   0 1052   13   37    2    9    3   12    7    0]\n",
      " [  18   35  817   58    8   15   21   31   21    8]\n",
      " [   8    9   34  860    5   30    7   30   16   11]\n",
      " [   5   25   13    8  799   22   10   23    6   71]\n",
      " [  18   12   23  101   29  636   18   34   15    6]\n",
      " [  33    7   41   12   24   48  782    6    2    3]\n",
      " [   4   28   23   26   16    3    4  901    2   21]\n",
      " [  25   27   40  103   18   83   23   38  581   36]\n",
      " [  20    9   22   29   58   26    4  125   17  699]]\n"
     ]
    }
   ],
   "source": [
    "# torch.manual_seed(6519)  # this seed scores really badly!\n",
    "# torch.manual_seed(666)\n",
    "\n",
    "device = torch.device(\"cpu\")\n",
    "drrn = DRRN(784, 10, 100, subnets=1, device=device)\n",
    "\n",
    "X = torch.from_numpy(train_X).float()\n",
    "y = torch.from_numpy(train_y).float()\n",
    "\n",
    "result = drrn.train(X, y)\n",
    "tX = torch.from_numpy(test_X).float()\n",
    "pred = drrn.predict(tX)\n",
    "pred_arg = np.zeros(10000)\n",
    "\n",
    "for i in range(len(pred)):\n",
    "    pred_arg[i] = np.argmax(pred[i])\n",
    "\n",
    "evaluation_summary('ELM', pred_arg, test_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([784, 250])\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "svd_cpu: The algorithm failed to converge because the input matrix is ill-conditioned or has too many repeated singular values (error code: 14).",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-7-a0d992a3562c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     11\u001b[0m     \u001b[0mX\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_numpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m     \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_numpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m     \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdoselm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     14\u001b[0m     \u001b[0mj\u001b[0m\u001b[0;34m+=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mj\u001b[0m\u001b[0;34m==\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/git_repos/lvl4-individual-project/src/utils/DOSELM.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self, X, y)\u001b[0m\n\u001b[1;32m     88\u001b[0m                 \u001b[0mH\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_activation\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtemp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_biases\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     89\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 90\u001b[0;31m             \u001b[0mH_pinv\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpinverse\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mH\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     91\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     92\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_datapoints\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: svd_cpu: The algorithm failed to converge because the input matrix is ill-conditioned or has too many repeated singular values (error code: 14)."
     ]
    }
   ],
   "source": [
    "torch.manual_seed(0)\n",
    "\n",
    "device = torch.device(\"cpu\")\n",
    "doselm = DOSELM(784, 10, [250], device=device)\n",
    "split_data = splitdata(train_X, train_y, 2)\n",
    "\n",
    "train_start = t.time()\n",
    "j = 0\n",
    "\n",
    "for i in split_data:\n",
    "    X = torch.from_numpy(i[0]).float()\n",
    "    y = torch.from_numpy(i[1]).float()\n",
    "    result = doselm.train(X,y)\n",
    "    j+=1\n",
    "    if j==0:\n",
    "        break\n",
    "train_end = t.time()\n",
    "\n",
    "tX = torch.from_numpy(test_X).float()\n",
    "\n",
    "pred_start = t.time()\n",
    "pred = doselm.predict(tX)\n",
    "pred_end = t.time()\n",
    "pred_arg = np.zeros(10000)\n",
    "\n",
    "for i in range(len(pred)):\n",
    "    pred_arg[i] = np.argmax(pred[i])\n",
    "\n",
    "evaluation_summary('ELM', pred_arg, test_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.manual_seed(0)\n",
    "\n",
    "device = torch.device(\"cpu\")\n",
    "doselm = DOSELM(784, 10, [1000], device=device)\n",
    "\n",
    "X = torch.from_numpy(train_X).float()[:60000]\n",
    "y = torch.from_numpy(train_y).float()[:60000]\n",
    "\n",
    "result = doselm.train(X, y)\n",
    "tX = torch.from_numpy(test_X).float()\n",
    "pred = doselm.predict(tX)\n",
    "pred_arg = np.zeros(10000)\n",
    "\n",
    "for i in range(len(pred)):\n",
    "    pred_arg[i] = np.argmax(pred[i])\n",
    "\n",
    "evaluation_summary('ELM', pred_arg, test_y)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
