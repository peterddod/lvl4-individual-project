{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Algorithm Testing\n",
    "A notebook used to compare algorithm performance.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Imports\n",
    "from nitools import utils \n",
    "from nitools.classifiers import PAE_RVFL, ELM, AE_ELM, PAE_ELM\n",
    "from nitools.models import LeNetPlus, LRF_ELM, LRF_ELMplus, MiniRes\n",
    "from nitools.operations import resetseed\n",
    "\n",
    "import numpy as np\n",
    "import random\n",
    "import torch\n",
    "import time as t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Import dataset\n",
    "mnist = utils.load_mnist(augment=True)\n",
    "\n",
    "mnist_in = 784\n",
    "mnist_class = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run(model, n=10000, nt=10000, data=mnist):\n",
    "    X = None\n",
    "    y = None \n",
    "    tX = None\n",
    "    try:\n",
    "        X = data['train_X'].float()[:n]\n",
    "        y = data['train_y'].float()[:n]\n",
    "        tX = data['test_X'].float()[:nt]\n",
    "    except:\n",
    "        X = data['train_X'].view((50000,3,32,32)).float()[:n]\n",
    "        y = torch.from_numpy(data['train_y']).float()[:n]\n",
    "        tX = data['test_X'].view((10000,3,32,32)).float()\n",
    "\n",
    "    train_start = t.time()\n",
    "    result = model.train(X, y)\n",
    "    train_end = t.time()\n",
    "    \n",
    "\n",
    "    test_start = t.time()\n",
    "    pred = model.predict(tX)\n",
    "    test_end = t.time()\n",
    "\n",
    "    pred_arg = np.zeros(nt)\n",
    "\n",
    "    for i in range(len(pred)):\n",
    "        pred_arg[i] = np.argmax(pred[i])\n",
    "\n",
    "\n",
    "    print(f\"train: {train_end-train_start}\")\n",
    "    print(f\"test: {test_end-test_start}\")\n",
    "    utils.evaluation_summary('lenet  - MNIST', pred_arg, data['test_y'][:nt])\n",
    "    \n",
    "def runos(model, b=5000, iters=1, nt=10000, data=mnist):\n",
    "    X = torch.from_numpy(data['train_X']).view((60000,1,28,28)).float()\n",
    "    y = torch.from_numpy(data['train_y']).float()\n",
    "\n",
    "    train_start = t.time()\n",
    "    for i in range(0,60000,b):\n",
    "        if i/b==iters:\n",
    "            break\n",
    "        result = model.train(X[i:i+b], y[i:i+b])\n",
    "    train_end = t.time()\n",
    "    \n",
    "    tX = torch.from_numpy(data['test_X']).view((10000,1,28,28)).float()\n",
    "\n",
    "    test_start = t.time()\n",
    "    pred = model.predict(tX)[:nt]\n",
    "    test_end = t.time()\n",
    "\n",
    "    pred_arg = np.zeros(nt)\n",
    "\n",
    "    for i in range(len(pred)):\n",
    "        pred_arg[i] = np.argmax(pred[i])\n",
    "\n",
    "\n",
    "    print(f\"train: {train_end-train_start}\")\n",
    "    print(f\"test: {test_end-test_start}\")\n",
    "    utils.evaluation_summary('lenet  - MNIST', pred_arg, data['test_y'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. MNIST\n",
    "\n",
    "Dataset of greyscale 28x28 images of handwritten digits. \n",
    "\n",
    "*Train: 60,000*, *Test: 10,000*, *10 Classes*, *784 Inputs*\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([5000, 3072])\n",
      "train: 7.541351318359375\n",
      "test: 9.585490942001343\n",
      "Evaluation for: lenet  - MNIST\n",
      "Classifier 'lenet  - MNIST' has Acc=0.981 P=0.981 R=0.981 F1=0.981\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0      0.996     0.986     0.991       990\n",
      "         1.0      0.994     0.987     0.990      1143\n",
      "         2.0      0.984     0.984     0.984      1031\n",
      "         3.0      0.985     0.981     0.983      1014\n",
      "         4.0      0.980     0.984     0.982       978\n",
      "         5.0      0.975     0.968     0.972       899\n",
      "         6.0      0.986     0.987     0.987       957\n",
      "         7.0      0.971     0.972     0.971      1027\n",
      "         8.0      0.976     0.985     0.981       965\n",
      "         9.0      0.964     0.977     0.971       996\n",
      "\n",
      "    accuracy                          0.981     10000\n",
      "   macro avg      0.981     0.981     0.981     10000\n",
      "weighted avg      0.981     0.981     0.981     10000\n",
      "\n",
      "\n",
      "Confusion matrix:\n",
      " [[ 976    0    0    0    1    1    1    0    1    0]\n",
      " [   0 1128    2    1    1    1    0    2    0    0]\n",
      " [   4    0 1015    1    0    0    2    7    3    0]\n",
      " [   0    0    0  995    0    8    0    6    1    0]\n",
      " [   0    1    0    0  962    0    5    0    1   13]\n",
      " [   3    2    0    7    1  870    3    2    3    1]\n",
      " [   4    3    0    0    3    2  945    0    1    0]\n",
      " [   0    7   11    3    3    0    0  998    1    5]\n",
      " [   3    0    2    6    0    3    1    4  951    4]\n",
      " [   0    2    1    1    7   14    0    8    3  973]]\n"
     ]
    }
   ],
   "source": [
    "data = utils.load_mnist(augment=False, label_smoothing=0.1)\n",
    "SEED = 2359487\n",
    "resetseed(SEED)\n",
    "\n",
    "model = LeNetPlus(c=1)\n",
    "\n",
    "run(model, n=5000, nt=10000, data=data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = utils.load_mnist(augment=False)\n",
    "SEED = 2359487\n",
    "resetseed(SEED)\n",
    "\n",
    "model = LRF_ELM(c=1000, _lambda=1, p=0)\n",
    "\n",
    "run(model, n=25000, nt=10000, data=data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. CIFAR-10\n",
    "\n",
    "Dataset of colour (3-dimension) 32x32 images of objects of 10 classes:\n",
    "\n",
    "0.\tairplane\n",
    "1.\tautomobile\n",
    "2.\tbird\n",
    "3.\tcat\n",
    "4.\tdeer\n",
    "5.\tdog\n",
    "6.\tfrog\n",
    "7.\thorse\n",
    "8.\tship\n",
    "9.\ttruck\n",
    "\n",
    "*Train: 60,000*, *Test: 10,000*, *10 Classes*, *784 Inputs*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import dataset\n",
    "cifar10 = utils.load_cifar10(scaled=True, augment=True)\n",
    "\n",
    "cifar_in = 32*32*3\n",
    "cifar_class = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.5802966356277466\n",
      "torch.Size([6480])\n",
      "0.8892340064048767\n",
      "torch.Size([6480])\n",
      "torch.Size([10000, 1280])\n"
     ]
    }
   ],
   "source": [
    "SEED = 22\n",
    "resetseed(SEED)\n",
    "\n",
    "model = LRF_ELMplus(in_channels=3, c=100, _lambda=np.sqrt(6))\n",
    "\n",
    "run(model, n=10000, nt=5000, data=cifar10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
