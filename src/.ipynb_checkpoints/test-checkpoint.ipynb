{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.datasets import mnist, cifar10\n",
    "# import tensorflow_datasets as tfds\n",
    "from utils.DOSELM import DOSELM\n",
    "from utils.DRRN import DRRN\n",
    "import numpy as np\n",
    "import torch\n",
    "import time as t\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.metrics import recall_score\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import fbeta_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluation_summary(description, predictions, true_labels):\n",
    "    print(\"Evaluation for: \" + description)\n",
    "    precision = precision_score(predictions, true_labels, average=\"macro\")\n",
    "    recall = recall_score(predictions, true_labels, average=\"macro\")\n",
    "    accuracy = accuracy_score(predictions, true_labels)\n",
    "    f1 = fbeta_score(predictions, true_labels, beta=1, average=\"macro\")\n",
    "    print(\"Classifier '%s' has Acc=%0.3f P=%0.3f R=%0.3f F1=%0.3f\" % (description,accuracy,precision,recall,f1))\n",
    "    print(classification_report(predictions, true_labels, digits=3))\n",
    "    print('\\nConfusion matrix:\\n',confusion_matrix(true_labels, predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scale(X):\n",
    "    return (X - X.mean())/(X.std()*10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def splitdata(x, y, splits=2, first=-1):\n",
    "    length = x.shape[0]\n",
    "\n",
    "    out = []\n",
    "    if first == -1:\n",
    "        splitlen = length // splits\n",
    "        for i in range(splits):\n",
    "            out.append((x[splitlen*i:splitlen*(i+1)], y[splitlen*i:splitlen*(i+1)]))\n",
    "    else:\n",
    "        splits-= 1\n",
    "        split1 = int(length*first)\n",
    "        splitn = (length-split1)//splits\n",
    "        out.append((x[0:split1], y[0:split1]))\n",
    "        for i in range(splits):\n",
    "            a = split1+splitn*i\n",
    "            b = split1+splitn*(i+1)\n",
    "            z = (x[a:b], y[a:b])\n",
    "            out.append(z)\n",
    "    return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "(train_X, train_y), (test_X, test_y) = cifar10.load_data()\n",
    "train_X = scale(np.reshape(train_X.ravel(), (-1,3072)))\n",
    "test_X = scale(np.reshape(test_X.ravel(), (-1,3072)))\n",
    "\n",
    "y = np.zeros([50000,10])\n",
    "\n",
    "for i in range(len(y)):\n",
    "    for j in range(len(y[i])):\n",
    "        if j == train_y[i]:\n",
    "            y[i,j] = 1\n",
    "        else:\n",
    "            y[i,j] = 0\n",
    "            \n",
    "train_y=y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10000\n",
      "Evaluation for: DRRN - MNIST\n",
      "Classifier 'DRRN - MNIST' has Acc=0.378 P=0.378 R=0.369 F1=0.366\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0      0.493     0.417     0.452      1183\n",
      "         1.0      0.463     0.382     0.419      1212\n",
      "         2.0      0.169     0.294     0.215       574\n",
      "         3.0      0.166     0.297     0.213       559\n",
      "         4.0      0.276     0.381     0.320       724\n",
      "         5.0      0.313     0.321     0.317       974\n",
      "         6.0      0.489     0.367     0.419      1332\n",
      "         7.0      0.366     0.410     0.387       893\n",
      "         8.0      0.557     0.417     0.477      1335\n",
      "         9.0      0.486     0.400     0.439      1214\n",
      "\n",
      "    accuracy                          0.378     10000\n",
      "   macro avg      0.378     0.369     0.366     10000\n",
      "weighted avg      0.415     0.378     0.390     10000\n",
      "\n",
      "\n",
      "Confusion matrix:\n",
      " [[493  61  23  25  12  19  24  48 216  79]\n",
      " [ 53 463  12  21  15  40  51  47 119 179]\n",
      " [134  62 169  50 124  88 167  85  74  47]\n",
      " [ 71  85  70 166  47 218 127  65  62  89]\n",
      " [ 73  45 100  48 276  90 199  91  44  34]\n",
      " [ 53  69  74 102  75 313 113  74  83  44]\n",
      " [ 28  73  60  70  84  72 489  51  22  51]\n",
      " [ 57  72  43  50  79  76  86 366  55 116]\n",
      " [155  90   9  15   3  40  21  21 557  89]\n",
      " [ 66 192  14  12   9  18  55  45 103 486]]\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cpu\")\n",
    "\n",
    "drrn = DRRN(3072, 10, 300, subnets=8, device=device, r=(0.05, 1))\n",
    "\n",
    "X = torch.from_numpy(train_X).float()[:50000]\n",
    "y = torch.from_numpy(train_y).float()[:50000]\n",
    "\n",
    "result = drrn.train(X, y)\n",
    "tX = torch.from_numpy(test_X).float()\n",
    "pred = drrn.predict(tX)[:10000]\n",
    "print(len(test_X))\n",
    "pred_arg = np.zeros(10000)\n",
    "\n",
    "for i in range(len(pred)):\n",
    "    pred_arg[i] = np.argmax(pred[i])\n",
    "\n",
    "evaluation_summary('DRRN - MNIST', pred_arg, test_y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A current problem with the algorithm, it seems, is that the algorithm can only learn roughly as well as the first representation created by the network. It can maintain its performance accross multiple layers but does not improve it. It is possible that improving the performance of the autoencoder might allow for better results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([784, 250])\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "svd_cpu: The algorithm failed to converge because the input matrix is ill-conditioned or has too many repeated singular values (error code: 14).",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-7-a0d992a3562c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     11\u001b[0m     \u001b[0mX\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_numpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m     \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_numpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m     \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdoselm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     14\u001b[0m     \u001b[0mj\u001b[0m\u001b[0;34m+=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mj\u001b[0m\u001b[0;34m==\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/git_repos/lvl4-individual-project/src/utils/DOSELM.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self, X, y)\u001b[0m\n\u001b[1;32m     88\u001b[0m                 \u001b[0mH\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_activation\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtemp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_biases\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     89\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 90\u001b[0;31m             \u001b[0mH_pinv\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpinverse\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mH\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     91\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     92\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_datapoints\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: svd_cpu: The algorithm failed to converge because the input matrix is ill-conditioned or has too many repeated singular values (error code: 14)."
     ]
    }
   ],
   "source": [
    "torch.manual_seed(0)\n",
    "\n",
    "device = torch.device(\"cpu\")\n",
    "doselm = DOSELM(784, 10, [250], device=device)\n",
    "split_data = splitdata(train_X, train_y, 2)\n",
    "\n",
    "train_start = t.time()\n",
    "j = 0\n",
    "\n",
    "for i in split_data:\n",
    "    X = torch.from_numpy(i[0]).float()\n",
    "    y = torch.from_numpy(i[1]).float()\n",
    "    result = doselm.train(X,y)\n",
    "    j+=1\n",
    "    if j==0:\n",
    "        break\n",
    "train_end = t.time()\n",
    "\n",
    "tX = torch.from_numpy(test_X).float()\n",
    "\n",
    "pred_start = t.time()\n",
    "pred = doselm.predict(tX)\n",
    "pred_end = t.time()\n",
    "pred_arg = np.zeros(10000)\n",
    "\n",
    "for i in range(len(pred)):\n",
    "    pred_arg[i] = np.argmax(pred[i])\n",
    "\n",
    "evaluation_summary('ELM', pred_arg, test_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.manual_seed(0)\n",
    "\n",
    "device = torch.device(\"cpu\")\n",
    "doselm = DOSELM(784, 10, [1000], device=device)\n",
    "\n",
    "X = torch.from_numpy(train_X).float()[:60000]\n",
    "y = torch.from_numpy(train_y).float()[:60000]\n",
    "\n",
    "result = doselm.train(X, y)\n",
    "tX = torch.from_numpy(test_X).float()\n",
    "pred = doselm.predict(tX)\n",
    "pred_arg = np.zeros(10000)\n",
    "\n",
    "for i in range(len(pred)):\n",
    "    pred_arg[i] = np.argmax(pred[i])\n",
    "\n",
    "evaluation_summary('ELM', pred_arg, test_y)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
